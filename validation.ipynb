{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import LeakyReLU, BatchNormalization, Input, Activation, Concatenate\n",
    "import numpy as np\n",
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "from keras.initializers import RandomNormal\n",
    "from numpy.random import randint\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_shape = (32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "  init = RandomNormal(stddev=0.02)\n",
    "  in_src_image = Input(shape=imgs_shape)\n",
    "  in_target_image = Input(shape=imgs_shape)\n",
    "  merged = Concatenate()([in_src_image, in_target_image])\n",
    "\n",
    "  d = tf.keras.layers.Conv2D(32, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "  d = LeakyReLU(alpha=0.2)(d)\n",
    "  \n",
    "  d = tf.keras.layers.Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "  d = BatchNormalization()(d)\n",
    "  d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "  d = tf.keras.layers.Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "  d = BatchNormalization()(d)\n",
    "  d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "  d = tf.keras.layers.Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "  d = BatchNormalization()(d)\n",
    "  d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "  d = tf.keras.layers.Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "  patch_out = Activation('sigmoid')(d)\n",
    "  \n",
    "  model = keras.models.Model([in_src_image, in_target_image], patch_out)\n",
    "\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "  model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    X = Input(shape = imgs_shape)\n",
    "  \n",
    "    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 5 , 5 ) , strides=1 )( X )\n",
    "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
    "    conv1 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n",
    "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1)( conv1 )\n",
    "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
    "    conv2 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n",
    "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D( 128 , kernel_size=( 5 , 5 ) , strides=1 )( conv2 )\n",
    "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
    "    conv3 = tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n",
    "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
    "\n",
    "    bottleneck = tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 , activation='tanh' , padding='same' )( conv3 )\n",
    "\n",
    "    concat_1 = tf.keras.layers.Concatenate()( [ bottleneck , conv3 ] )\n",
    "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_1 )\n",
    "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' )( conv_up_3 )\n",
    "\n",
    "    concat_2 = tf.keras.layers.Concatenate()( [ conv_up_3 , conv2 ] )\n",
    "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_2 )\n",
    "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' )( conv_up_2 )\n",
    "\n",
    "    concat_3 = tf.keras.layers.Concatenate()( [ conv_up_2 , conv1 ] )\n",
    "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu')( concat_3 )\n",
    "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 3 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu')( conv_up_1 )\n",
    "  \n",
    "    model = tf.keras.models.Model( X , conv_up_1 )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "  data = np.load(filename)\n",
    "  X1, X2 = data[\"arr_0\"], data[\"arr_1\"]\n",
    "  X1 = (X1 - 127.5)/127.5\n",
    "  X2 = (X2 - 127.5)/127.5\n",
    "  return [X1,X2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_images(dataset, n, patch_shape):\n",
    "  trainA, trainB = dataset\n",
    "  ix = randint(0, trainA.shape[0],n)\n",
    "  X1, X2 = trainA[ix], trainB[ix]\n",
    "  y = ones((n, patch_shape, patch_shape,1))\n",
    "  return [X1,X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_images(model, sample, patch_shape):\n",
    "  X = model.predict(sample)\n",
    "  y = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "  return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('dataset\\cifar10.npz')\n",
    "print(\"Loaded\", dataset[0].shape, dataset[1].shape)\n",
    "image_shape = dataset[0].shape[1:]\n",
    "disc_model = discriminator()\n",
    "gen_model = generator() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model.load_weights(\"..\\Weights\\model_060.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "#dataset = load_dataset('cifar10.npz')\n",
    "\n",
    "[realA, realB], _ = generate_real_images(dataset, n, 1)\n",
    "fakeB, _ = generate_fake_images(gen_model, realA, 1)\n",
    "realA = (realA+1)/2.0\n",
    "realB = (realB+1)/2.0\n",
    "fakeB = (fakeB+1)/2.0\n",
    "\n",
    "# plot real source images\n",
    "for i in range(n):\n",
    "  pyplot.subplot(3, n, 1+i)\n",
    "  pyplot.axis(\"off\")\n",
    "  pyplot.imshow(realA[i])\n",
    "  \n",
    "#plot generated target images  \n",
    "for i in range(n):\n",
    "  pyplot.subplot(3, n, 1+n+i)\n",
    "  pyplot.axis(\"off\")\n",
    "  pyplot.imshow(fakeB[i])\n",
    "\n",
    "# plot real target images\n",
    "for i in range(n):\n",
    "  pyplot.subplot(3, n, 1+n*2+i)\n",
    "  pyplot.axis(\"off\")\n",
    "  pyplot.imshow(realB[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
